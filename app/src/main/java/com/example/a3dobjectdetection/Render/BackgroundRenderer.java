package com.example.a3dobjectdetection.Render;

import com.google.ar.core.Coordinates2d;
import com.google.ar.core.Frame;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.FloatBuffer;
import java.util.HashMap;

//在ondraw中绘制Frame对象的内容  这个类既渲染了AR相机的背景，也构成了场景的前景。
public class BackgroundRenderer {

    private static final String TAG = BackgroundRenderer.class.getSimpleName();
    private final Texture cameraDepthTexture;//相机深度和颜色纹理
    private final Texture cameraColorTexture;
    //每个顶点的组件*顶点的数量*float字节数
    // components_per_vertex * number_of_vertices * float_size
    private static final int COORDS_BUFFER_SIZE = 2 * 4 * 4;

    private static final FloatBuffer NDC_QUAD_COORDS_BUFFER = //  ByteBuffer.allocateDirect系统级的内存分配
            ByteBuffer.allocateDirect(COORDS_BUFFER_SIZE).order(ByteOrder.nativeOrder()).asFloatBuffer();//asFloatBuffer()创建对应的视图缓冲区
    ////order定义了写入buffer时字节的顺序
    private static final FloatBuffer VIRTUAL_SCENE_TEX_COORDS_BUFFER =
            ByteBuffer.allocateDirect(COORDS_BUFFER_SIZE).order(ByteOrder.nativeOrder()).asFloatBuffer();

    private final FloatBuffer cameraTexCoords =
            ByteBuffer.allocateDirect(COORDS_BUFFER_SIZE).order(ByteOrder.nativeOrder()).asFloatBuffer();
    static {
        NDC_QUAD_COORDS_BUFFER.put(
                new float[] {
                        /*0:*/ -1f, -1f, /*1:*/ +1f, -1f, /*2:*/ -1f, +1f, /*3:*/ +1f, +1f,
                });
        VIRTUAL_SCENE_TEX_COORDS_BUFFER.put(
                new float[] {
                        /*0:*/ 0f, 0f, /*1:*/ 1f, 0f, /*2:*/ 0f, 1f, /*3:*/ 1f, 1f,
                });
    }

    private final VertexBuffer cameraTexCoordsVertexBuffer;
    private final Mesh mesh;
    private Shader backgroundShader;
    private Shader occlusionShader;

    public BackgroundRenderer(SampleRender render) {
        cameraColorTexture =
                new Texture(
                        render,
                        Texture.Target.TEXTURE_EXTERNAL_OES,
                        Texture.WrapMode.CLAMP_TO_EDGE,
                        /*useMipmaps=*/ false);
        cameraDepthTexture =
                new Texture(
                        render,
                        Texture.Target.TEXTURE_2D,
                        Texture.WrapMode.CLAMP_TO_EDGE,
                        /*useMipmaps=*/ false);


        //创建一个带有三个顶点缓冲的网格:一个用于屏幕坐标(标准化设备坐标)，
        //一个用于摄像机纹理坐标(在绘制之前填充适当的数据)，一个用于虚拟场景纹理坐标(单位纹理四边形)
        VertexBuffer screenCoordsVertexBuffer =
                new VertexBuffer(render, /* numberOfEntriesPerVertex=*/ 2, NDC_QUAD_COORDS_BUFFER);
        cameraTexCoordsVertexBuffer =
                new VertexBuffer(render, /*numberOfEntriesPerVertex=*/ 2, /*entries=*/ null);
        VertexBuffer virtualSceneTexCoordsVertexBuffer =
                new VertexBuffer(render, /* numberOfEntriesPerVertex=*/ 2, VIRTUAL_SCENE_TEX_COORDS_BUFFER);
        VertexBuffer[] vertexBuffers = {
                screenCoordsVertexBuffer, cameraTexCoordsVertexBuffer, virtualSceneTexCoordsVertexBuffer,
        };
        mesh =
                new Mesh(render, Mesh.PrimitiveMode.TRIANGLE_STRIP, /*indexBuffer=*/ null, vertexBuffers);

    }

    public void setbackgroundshader(SampleRender render)
            throws IOException {
        if (backgroundShader != null) {
           return;
        }
        backgroundShader =
                Shader.createFromAssets(render, "shaders/background_show_camera.vert",
                        "shaders/background_show_camera.frag",
                        /*defines=*/ null)
                        .setTexture("u_CameraColorTexture", cameraColorTexture)
                        .setDepthTest(false)
                        .setDepthWrite(false);

    }
    //更新显示的视图
    public void updateDisplayGeometry(Frame frame) {
        if (frame.hasDisplayGeometryChanged()) {
            //检查显示旋转或视口几何形状是否自前一帧改变
            // If display rotation changed (also includes view size change), we need to re-query the UV
            // coordinates for the screen rect, as they may have changed as well.
            frame.transformCoordinates2d(
                    //转移2d坐标
                    Coordinates2d.OPENGL_NORMALIZED_DEVICE_COORDINATES,
                    NDC_QUAD_COORDS_BUFFER,
                    Coordinates2d.TEXTURE_NORMALIZED,
                    cameraTexCoords);
            cameraTexCoordsVertexBuffer.set(cameraTexCoords);
        }
    }

    public void drawBackground(SampleRender render) {
        render.draw(mesh, backgroundShader);
    }

    /** Return the camera color texture generated by this object. */
    public Texture getCameraColorTexture() {
        return cameraColorTexture;
    }

    /** Return the camera depth texture generated by this object. */
    public Texture getCameraDepthTexture() {
        return cameraDepthTexture;
    }
}
